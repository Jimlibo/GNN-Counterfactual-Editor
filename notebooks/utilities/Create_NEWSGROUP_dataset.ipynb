{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cc7e37-c01b-4153-ae94-763ed9486194",
   "metadata": {},
   "source": [
    "# Create NEWSGROUP Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f358b388-81c1-4363-a1c9-cbb941717d64",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d14d19-5653-4ab6-a7fd-2657710e73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4878b-a569-4aad-a88e-087caa6a994d",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4172697-57b7-4ba8-8fda-5ae1e3c46ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = '../../Data/NEWSGROUPS/train/newsgroups_train.csv'\n",
    "TEST_CSV = '../../Data/NEWSGROUPS/test/newsgroups_test.csv'\n",
    "TRAIN_VAL_SPLIT_RATIO = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa7974-58db-4ccb-8f14-46759a897f20",
   "metadata": {},
   "source": [
    "## Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b447f72-3b5e-4aa9-b064-464045696b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, special_chars=[\"\\n\", \"\\t\"]):\n",
    "    for char in special_chars:\n",
    "        text = text.replace(char, \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44e3fec4-9656-450f-ba8a-3c261ed52eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_indices(subset):\n",
    "        np.random.seed(0)\n",
    "    \n",
    "        newsgroups_data = fetch_20newsgroups(\n",
    "                subset=subset, remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "    \n",
    "        data_indices = np.array(range(len(newsgroups_data.data))) \n",
    "        np.random.shuffle(data_indices)\n",
    "    \n",
    "        return data_indices, newsgroups_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7acc9d8f-baea-4c42-a04d-420da4f701de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(subset):\n",
    "        np.random.seed(0)\n",
    "        data_indices, newsgroups_data = get_data_indices(subset)\n",
    "        strings = [None] * len(data_indices)\n",
    "        labels = [None] * len(data_indices)\n",
    "        for i, idx in enumerate(data_indices):\n",
    "            txt = newsgroups_data.data[idx]\n",
    "            topic = newsgroups_data.target[idx]\n",
    "            label = newsgroups_data['target_names'][topic].split(\".\")[0]\n",
    "            txt = clean_text(txt, special_chars=[\"\\n\", \"\\t\"])\n",
    "            if len(txt) == 0 or len(label) == 0:\n",
    "                strings[i] = None\n",
    "                labels[i] = None\n",
    "            else:\n",
    "                strings[i] = txt\n",
    "                labels[i] = label\n",
    "\n",
    "        strings = [x for x in strings if x is not None]\n",
    "        labels = [x for x in labels if x is not None]\n",
    "        assert len(strings) == len(labels)\n",
    "    \n",
    "        return strings, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b824d5-2f15-4b1a-a693-3d889c129e67",
   "metadata": {},
   "source": [
    "## Create Training CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d8ddf9c-b66d-4092-88e2-a591899be1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text, labels = get_inputs('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d72faf93-1e99-4cd5-bece-c63386c5a7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text labels\n",
      "0  [Most info regarding dangers of reading from F...   comp\n",
      "1  Attention hardware hackers and bargain seekers...    sci\n",
      "2  A friend's daughter has been diagnosed with an...    sci\n",
      "3  WHile we are on the subject of the shuttle sof...    sci\n",
      "4    That is great to hear I just may have to tak...    rec\n",
      "\n",
      "Training Dataframe has shape: (11096, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame({\n",
    "    'text': text,\n",
    "    'labels': labels\n",
    "})\n",
    "\n",
    "print(train_df.head())\n",
    "print(\"\\nTraining Dataframe has shape: {}\".format(train_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc63ea58-e49d-41ab-9248-abe6ad673a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/'.join(TRAIN_CSV.split('/')[:-1])\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    os.makedirs(TRAIN_DIR)\n",
    "    \n",
    "train_df.to_csv(TRAIN_CSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0547f9-4f62-44f3-861d-dd1a22ccfec4",
   "metadata": {},
   "source": [
    "## Create Testing CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cca2cae7-64a0-4b2b-8cf5-bd3f88d04f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "text, labels = get_inputs('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f26c1cb7-3bbf-4ee2-9f5d-13ea336735cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text labels\n",
      "0  David Hammerslag asked:   How do you (Mormons)...    soc\n",
      "1  In the article \"At last! Now you can talk to y...    sci\n",
      "2  Sci med people:   Can I sell my TENS unit or d...    sci\n",
      "3  [...]  OK Steve, here's a sketch of an alterna...    sci\n",
      "4    Low oil pressure, usually.  Could be your oi...    rec\n",
      "\n",
      "Testing Dataframe has shape: (7370, 2)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame({\n",
    "    'text': text,\n",
    "    'labels': labels\n",
    "})\n",
    "\n",
    "print(test_df.head())\n",
    "print(\"\\nTesting Dataframe has shape: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab525b07-bfd2-47e5-a410-97e66f8e4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = '/'.join(TEST_CSV.split('/')[:-1])\n",
    "if not os.path.exists(TEST_DIR):\n",
    "    os.makedirs(TEST_DIR)\n",
    "    \n",
    "train_df.to_csv(TEST_CSV, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
